{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"210322_강화학습3장.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMuk32+P1L1WfMk0UaYw0vz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"bQksKHx09-4x","executionInfo":{"status":"ok","timestamp":1617432432787,"user_tz":-540,"elapsed":1114,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}}},"source":["import numpy as np\n","import random\n","import sys\n","\n","def randPair(s,e):\n","    return np.random.randint(s,e), np.random.randint(s,e)\n","\n","class BoardPiece:\n","\n","    def __init__(self, name, code, pos):\n","        self.name = name #name of the piece\n","        self.code = code #an ASCII character to display on the board\n","        self.pos = pos #2-tuple e.g. (1,4)\n","\n","class BoardMask:\n","\n","    def __init__(self, name, mask, code):\n","        self.name = name\n","        self.mask = mask\n","        self.code = code\n","\n","    def get_positions(self): #returns tuple of arrays\n","        return np.nonzero(self.mask)\n","\n","def zip_positions2d(positions): #positions is tuple of two arrays\n","    x,y = positions\n","    return list(zip(x,y))\n","\n","class GridBoard:\n","\n","    def __init__(self, size=4):\n","        self.size = size #Board dimensions, e.g. 4 x 4\n","        self.components = {} #name : board piece\n","        self.masks = {}\n","\n","    def addPiece(self, name, code, pos=(0,0)):\n","        newPiece = BoardPiece(name, code, pos)\n","        self.components[name] = newPiece\n","\n","    #basically a set of boundary elements\n","    def addMask(self, name, mask, code):\n","        #mask is a 2D-numpy array with 1s where the boundary elements are\n","        newMask = BoardMask(name, mask, code)\n","        self.masks[name] = newMask\n","\n","    def movePiece(self, name, pos):\n","        move = True\n","        for _, mask in self.masks.items():\n","            if pos in zip_positions2d(mask.get_positions()):\n","                move = False\n","        if move:\n","            self.components[name].pos = pos\n","\n","    def delPiece(self, name):\n","        del self.components['name']\n","\n","    def render(self):\n","        dtype = '<U2'\n","        displ_board = np.zeros((self.size, self.size), dtype=dtype)\n","        displ_board[:] = ' '\n","\n","        for name, piece in self.components.items():\n","            displ_board[piece.pos] = piece.code\n","\n","        for name, mask in self.masks.items():\n","            displ_board[mask.get_positions()] = mask.code\n","\n","        return displ_board\n","\n","    def render_np(self):\n","        num_pieces = len(self.components) + len(self.masks)\n","        displ_board = np.zeros((num_pieces, self.size, self.size), dtype=np.uint8)\n","        layer = 0\n","        for name, piece in self.components.items():\n","            pos = (layer,) + piece.pos\n","            displ_board[pos] = 1\n","            layer += 1\n","\n","        for name, mask in self.masks.items():\n","            x,y = self.masks['boundary'].get_positions()\n","            z = np.repeat(layer,len(x))\n","            a = (z,x,y)\n","            displ_board[a] = 1\n","            layer += 1\n","        return displ_board\n","\n","def addTuple(a,b):\n","    return tuple([sum(x) for x in zip(a,b)])"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"BJBXg_x793I_","executionInfo":{"status":"ok","timestamp":1617432434977,"user_tz":-540,"elapsed":1677,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}}},"source":["\n","class Gridworld:\n","\n","    def __init__(self, size=4, mode='static'):\n","        if size >= 4:\n","            self.board = GridBoard(size=size)\n","        else:\n","            print(\"Minimum board size is 4. Initialized to size 4.\")\n","            self.board = GridBoard(size=4)\n","\n","        #Add pieces, positions will be updated later\n","        self.board.addPiece('Player','P',(0,0))\n","        self.board.addPiece('Goal','+',(1,0))\n","        self.board.addPiece('Pit','-',(2,0))\n","        self.board.addPiece('Wall','W',(3,0))\n","\n","        if mode == 'static':\n","            self.initGridStatic()\n","        elif mode == 'player':\n","            self.initGridPlayer()\n","        else:\n","            self.initGridRand()\n","\n","    #Initialize stationary grid, all items are placed deterministically\n","    def initGridStatic(self):\n","        #Setup static pieces\n","        self.board.components['Player'].pos = (0,3) #Row, Column\n","        self.board.components['Goal'].pos = (0,0)\n","        self.board.components['Pit'].pos = (0,1)\n","        self.board.components['Wall'].pos = (1,1)\n","\n","    #Check if board is initialized appropriately (no overlapping pieces)\n","    #also remove impossible-to-win boards\n","    def validateBoard(self):\n","        valid = True\n","\n","        player = self.board.components['Player']\n","        goal = self.board.components['Goal']\n","        wall = self.board.components['Wall']\n","        pit = self.board.components['Pit']\n","\n","        all_positions = [piece for name,piece in self.board.components.items()]\n","        all_positions = [player.pos, goal.pos, wall.pos, pit.pos]\n","        if len(all_positions) > len(set(all_positions)):\n","            return False\n","\n","        corners = [(0,0),(0,self.board.size), (self.board.size,0), (self.board.size,self.board.size)]\n","        #if player is in corner, can it move? if goal is in corner, is it blocked?\n","        if player.pos in corners or goal.pos in corners:\n","            val_move_pl = [self.validateMove('Player', addpos) for addpos in [(0,1),(1,0),(-1,0),(0,-1)]]\n","            val_move_go = [self.validateMove('Goal', addpos) for addpos in [(0,1),(1,0),(-1,0),(0,-1)]]\n","            if 0 not in val_move_pl or 0 not in val_move_go:\n","                #print(self.display())\n","                #print(\"Invalid board. Re-initializing...\")\n","                valid = False\n","\n","        return valid\n","\n","    #Initialize player in random location, but keep wall, goal and pit stationary\n","    def initGridPlayer(self):\n","        #height x width x depth (number of pieces)\n","        self.initGridStatic()\n","        #place player\n","        self.board.components['Player'].pos = randPair(0,self.board.size)\n","\n","        if (not self.validateBoard()):\n","            #print('Invalid grid. Rebuilding..')\n","            self.initGridPlayer()\n","\n","    #Initialize grid so that goal, pit, wall, player are all randomly placed\n","    def initGridRand(self):\n","        #height x width x depth (number of pieces)\n","        self.board.components['Player'].pos = randPair(0,self.board.size)\n","        self.board.components['Goal'].pos = randPair(0,self.board.size)\n","        self.board.components['Pit'].pos = randPair(0,self.board.size)\n","        self.board.components['Wall'].pos = randPair(0,self.board.size)\n","\n","        if (not self.validateBoard()):\n","            #print('Invalid grid. Rebuilding..')\n","            self.initGridRand()\n","\n","    def validateMove(self, piece, addpos=(0,0)):\n","        outcome = 0 #0 is valid, 1 invalid, 2 lost game\n","        pit = self.board.components['Pit'].pos\n","        wall = self.board.components['Wall'].pos\n","        new_pos = addTuple(self.board.components[piece].pos, addpos)\n","        if new_pos == wall:\n","            outcome = 1 #block move, player can't move to wall\n","        elif max(new_pos) > (self.board.size-1):    #if outside bounds of board\n","            outcome = 1\n","        elif min(new_pos) < 0: #if outside bounds\n","            outcome = 1\n","        elif new_pos == pit:\n","            outcome = 2\n","\n","        return outcome\n","\n","    def makeMove(self, action):\n","        #need to determine what object (if any) is in the new grid spot the player is moving to\n","        #actions in {u,d,l,r}\n","        def checkMove(addpos):\n","            if self.validateMove('Player', addpos) in [0,2]:\n","                new_pos = addTuple(self.board.components['Player'].pos, addpos)\n","                self.board.movePiece('Player', new_pos)\n","\n","        if action == 'u': #up\n","            checkMove((-1,0))\n","        elif action == 'd': #down\n","            checkMove((1,0))\n","        elif action == 'l': #left\n","            checkMove((0,-1))\n","        elif action == 'r': #right\n","            checkMove((0,1))\n","        else:\n","            pass\n","\n","    def reward(self):\n","        if (self.board.components['Player'].pos == self.board.components['Pit'].pos):\n","            return -10\n","        elif (self.board.components['Player'].pos == self.board.components['Goal'].pos):\n","            return 10\n","        else:\n","            return -1\n","\n","    def display(self):\n","        return self.board.render()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"7BIuFPwz-eb3","executionInfo":{"status":"ok","timestamp":1617432435845,"user_tz":-540,"elapsed":1208,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}}},"source":["import numpy as np\n","import torch\n","from IPython.display import clear_output\n","import random\n","from matplotlib import pylab as plt"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"5mhkzRU_oaKF","executionInfo":{"status":"ok","timestamp":1617432437063,"user_tz":-540,"elapsed":505,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}}},"source":["\n","l1 = 64\n","l2 = 150\n","l3 = 100\n","l4 = 4\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(l1, l2),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(l2, l3),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(l3,l4)\n",")\n","loss_fn = torch.nn.MSELoss()\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","gamma = 0.9\n","epsilon = 1.0\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","gamma = 0.9\n","epsilon = 1.0"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHyn7j0c-Bbm","executionInfo":{"status":"ok","timestamp":1616486066535,"user_tz":-540,"elapsed":882,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"3a591efa-7c91-4d1f-f850-9b42aa6c1672"},"source":["game = Gridworld(size=4, mode='static')\n","game.display()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['+', '-', ' ', 'P'],\n","       [' ', 'W', ' ', ' '],\n","       [' ', ' ', ' ', ' '],\n","       [' ', ' ', ' ', ' ']], dtype='<U2')"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aye6gwK1-O4s","executionInfo":{"status":"ok","timestamp":1616400422184,"user_tz":-540,"elapsed":477,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"3a74fda7-34d0-4577-84d9-0d2623ba808c"},"source":["game.makeMove('d')\n","game.makeMove('d')\n","game.makeMove('l')\n","game.display()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['+', '-', ' ', ' '],\n","       [' ', 'W', ' ', ' '],\n","       [' ', ' ', 'P', ' '],\n","       [' ', ' ', ' ', ' ']], dtype='<U2')"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TCQ4Htfb-RL5","executionInfo":{"status":"ok","timestamp":1616400429061,"user_tz":-540,"elapsed":531,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"5b526518-c94d-4500-8eea-c0d6a907b06e"},"source":["game.reward()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-1"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tEECJGT6-S2o","executionInfo":{"status":"ok","timestamp":1616486071715,"user_tz":-540,"elapsed":734,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"4c15ecd8-cdc2-46ad-b19a-ec3a654d1430"},"source":["\n","game.board.render_np()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0, 0, 0, 1],\n","        [0, 0, 0, 0],\n","        [0, 0, 0, 0],\n","        [0, 0, 0, 0]],\n","\n","       [[1, 0, 0, 0],\n","        [0, 0, 0, 0],\n","        [0, 0, 0, 0],\n","        [0, 0, 0, 0]],\n","\n","       [[0, 1, 0, 0],\n","        [0, 0, 0, 0],\n","        [0, 0, 0, 0],\n","        [0, 0, 0, 0]],\n","\n","       [[0, 0, 0, 0],\n","        [0, 1, 0, 0],\n","        [0, 0, 0, 0],\n","        [0, 0, 0, 0]]], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"JxC2W76k-UCV"},"source":["action_set = {\n","    0: 'u',\n","    1: 'd',\n","    2: 'l',\n","    3: 'r',\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIe1j-qL-YOo","executionInfo":{"status":"ok","timestamp":1616400948402,"user_tz":-540,"elapsed":253253,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"57f0643a-429c-430d-d6d6-fc258fb21675"},"source":["epochs = 1000\n","losses = [] #A # 손실을 관찰하기 위해 손실을 리스트에 담는다.\n","for i in range(epochs): #B \n","# epochs 만큼 게임을 반복한다.\n","    game = Gridworld(size=4, mode='static') #C \n","    # 게임을 'static' 방식으로 시작한다.\n","    state_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0 #D\n","    # 현재 상태를 numpy 배열로 표현하고 1,64 배열로 정돈한다.\n","    # 그리고 죽은 셀을 방지하기 위해 잡음을 조금 넣어준다.\n","    state = torch.from_numpy(state_).float() #E\n","    # 현재 상태에 대한 numpy 배열을 pytorch 에서 사용가능한 배열로 바꿔준다. (float())\n","    state1 = torch.from_numpy(state_).float()\n","    # 현재 상태를 state1 에 담아준다.\n","    status = 1 #F\n","    # 초기상태를 1로 지정을 한다. (이기거나 지면 status 값이 바뀐다.)\n","    while(status == 1): #G\n","    # 이기거나 지지 않은 상태일 경우\n","        qval = model(state1) #H\n","        # 첫번째로, model(인공신경망)이 가치예측판단을 한다.\n","        qval_ = qval.data.numpy()\n","        # 4개의 선택에 대해서 어느정도의 예상보상이 있는지 출력한 것을\n","        # numpy 배열로 바꿔준다.\n","        if (random.random() < epsilon): #I\n","            action_ = np.random.randint(0,4)\n","            # epsilon 의 확률로 랜덤행동을 하고,\n","        else:\n","            action_ = np.argmax(qval_)\n","            # 그 외의 확률로는 신경망이 판단한 최선의 선택을 한다.\n","        \n","        action = action_set[action_] #J\n","        # 해당 행동 numpy 를 'u','d','l','r' 형태의 문자열로 변경해준다.\n","        game.makeMove(action) #K\n","        # 해당 문자열로 움직인다.\n","        state2_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n","        # 움직이고 난 상태를 numpy로 바꾸고, 1,64 배열로 바꿔준 후 잡음을 더해 state2 에 저장해준다.\n","        state2 = torch.from_numpy(state2_).float() #L\n","        # 상태2를 pytorch 형 배열로 바꾼 다음 state2 에 담아준다.\n","        reward = game.reward()\n","        # state2 에서의 보상을 업데이트 시켜준다.\n","        with torch.no_grad():\n","          # 결과값만을 얻기 위해 no_grad 를 해준다. (역전파가 필요 없는 경우)\n","            newQ = model(state2.reshape(1,64))\n","            # 상태2 에서 신경망이 판단한 보상예측을 newQ에 담는다.\n","        maxQ = torch.max(newQ) #M\n","        # 상태2 에서의 최선의 보상을 maxQ(최대 보상)에 대입한다.\n","        if reward == -1: #N\n","        # 만약 reward 가 -1, 즉 이동만 하고 구덩이나 +를 밟지 않은 경우라면\n","            Y = reward + (gamma * maxQ)\n","            # 보상에 gamma(시간상쇄지수)*최대보상을 더해준다.\n","        else:\n","            Y = reward\n","            # 만약 구덩이나 +를 밟은 경우라면 Y에 보상을 바로 집어넣는다.\n","        Y = torch.Tensor([Y]).detach()\n","        # .detach() 는 해당 텐서를 복사해주는 기능이다. (복사된 텐서는 gradient 전파가 안된다.)\n","        # no_grad 와 detach 는 똑같다. 둘 다 requires_grad 를 False 로 만들어주는 기능.\n","        # 따라서 Y에 보상값을 torch 텐서로 변형해준 값을 복사해서 담아준다.\n","        \n","        X = qval.squeeze()[action_] #O\n","        # squeeze 메소드는 더미의 차원을 추가하는 기능이고,\n","        # unsqueeze 는 더미의 차원을 삭제하는 기능이다.\n","        # 즉 여기선 qval 이라는 가치판단 함수에 행동[0 0 1 0]을 넣어주게 된다.\n","        # 그래서 해당 행동을 했다는 것을 알리기 위함이다.\n","        # 여기서 action_ 예를 들면 2번 행동을 했으면,\n","        # 2번 행동에 해당하는 가치값을 X에 대입해줌을 말한다.\n","\n","        loss = loss_fn(X, Y) #P\n","        # qval = model(state1), Y =torch.Tensor([reward (+ gamma*maxQ 선택)])\n","        # 즉 신경망이 예측한 보상들과 실제 보상들의 손실을 계산한다.\n","        # X는 qval(신경망이 기대한 가치들)에서 해당 행동에 해당하는 기대되는 가치를 대입한 값이고,\n","        # Y는 실제 보상이다.\n","        # 그래서 그 기대값과 실제 보상을 손실함수를 통해 손실을 구하고,\n","        # 이를 나중에 역전파 해서 신경망의 가중치를 바꾼다.\n","\n","        print(i, loss.item())\n","        # 게임 횟수에 따른 손실값을 출력한다.\n","        clear_output(wait=True)\n","        # 화면에 출력된걸 다 지워서 깔끔하게 만든다.\n","        optimizer.zero_grad()\n","        # 최적기안에 탑재된 매개변수를 모두 0으로 만든다. \n","        # 이게 왜 필요한가?\n","        # 파이토치는 미분을 통해 얻은 기울기를 이전에 계산된 기울기 값에 누적시키는 특징이 있다.\n","        # 따라서 매회마다 초기화를 시켜줘야 한다. (? 이해 안감.)\n","        # no_grad 와 zero_grad 는 다름.\n","        # zero_grad 는 초기화고, no_grad 는 아예 gradient 를 만들지 않도록 설정함.\n","\n","        loss.backward()\n","        # 계산을 통해 얻은 grad(경사)을 통해서 \n","        # model의 매개변수를 역전파를 하는 기능. \n","        losses.append(loss.item())\n","        # 손실을 담아준다. ( loss.item() 은 손실함수에서 손실값을 산출하는 기능이다. )\n","        optimizer.step()\n","        # optimizer 은 계산을 통해 축적된 손실과 grad 을 통해 model 안의 모든 tensor 을 순환하여 \n","        # 가중치를 조정하고\n","        # 이로 인해 model 은 진화한다.\n","        state1 = state2\n","        # 상태 1을 2로 바꿔준다.\n","        if reward != -1: #Q\n","            status = 0\n","            # 만약 구덩이에 빠졌거나 이겼으면 status = 0으로 한다.\n","    if epsilon > 0.1: #R\n","        epsilon -= (1/epochs)\n","        # epsilon 값을 횟수가 지나가면 지나갈수록 갱신해준다.\n","        # 초기입실론값 - 1/1000 - 1/1000 ... "],"execution_count":null,"outputs":[{"output_type":"stream","text":["999 0.013151569291949272\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"id":"Wdmbtt8q-ayF","executionInfo":{"status":"ok","timestamp":1616401105219,"user_tz":-540,"elapsed":916,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"a0035732-a5f9-4bcc-970e-a6eb714ca189"},"source":["# 손실의 변화 추이를 찍어서 관찰하자.\n","\n","plt.figure(figsize=(10,7))\n","plt.plot(losses)\n","plt.xlabel(\"Epochs\",fontsize=22)\n","plt.ylabel(\"Loss\",fontsize=22)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, 'Loss')"]},"metadata":{"tags":[]},"execution_count":20},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAm4AAAGzCAYAAACW4Jt/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcV33//9fHknc7drzEcWwnDlkISUsWDAQCFMIaoARooVDKXlK+DS10+ZWErdDCl1AaKFvhm0AgUEJYQ0JJSEL21Y6TOI7tLN73WJJly7Itaz2/P+bKjGVJlmWNZu7o9Xw89NDMmTszn7kaSe8559xzI6WEJEmSKt+ochcgSZKkgTG4SZIk5YTBTZIkKScMbpIkSTlhcJMkScqJ2nIXMBxmzJiR5s+fX+4yJEmSDunhhx9uSCnN7O22ERHc5s+fz+LFi8tdhiRJ0iFFxPq+bnOoVJIkKScMbpIkSTlhcJMkScoJg5skSVJOGNwkSZJywuAmSZKUEwY3SZKknDC4SZIk5UTZg1tEjIuIRRHxWEQsj4jPZe0/iIi1EbEk+zora4+I+HpErIqIpRFxTnlfgSRJ0vCohDMntALnp5R2R8Ro4N6IuCm77f9LKf2ix/YXAKdkXy8Evp19lyRJqmpl73FLBbuzq6Ozr9TPXS4Efpjd70FgakTMLnWdkiRJ5Vb24AYQETURsQSoA25NKS3MbvpCNhz61YgYm7XNATYW3X1T1tbzMS+KiMURsbi+vr6k9UuSJA2HighuKaXOlNJZwFzgBRHxR8ClwGnA84FpwMcP8zGvSCktSCktmDlz5pDXLEmSNNwqIrh1SyntBO4AXpdS2poNh7YC3wdekG22GZhXdLe5WZskSVJVK3twi4iZETE1uzweeDXwZPe8tYgI4M3AsuwuNwDvyY4uPRdoSiltLUPpJdXU0l7uEiRJUoUpe3ADZgN3RMRS4CEKc9z+F/hxRDwOPA7MAD6fbX8jsAZYBVwJ/O3wl1xayzY3cebnbuGGx7aUuxRJklRByr4cSEppKXB2L+3n97F9Ai4udV3ltHxLEwD3rqznTWceV+ZqJElSpaiEHjdJkiQNgMFNkiQpJwxukiRJOWFwkyRJygmDmyRJUk4Y3CRJknLC4CZJkpQTBjdJkqScMLhJkiTlhMFNkiQpJwxukiRJOWFwkyRJygmDmyRJUk4Y3CRJknLC4CZJkpQTBjdJkqScMLhJkiTlhMFNkiQpJwxukiRJOWFwkyRJygmDmyRJUk4Y3CRJknLC4FYC/++u1ayqay53GZIkqcoY3IZYe2cXX7zpSd7yrfuP+LFSGoKCJElS1TC4lUhLe+eg7xvEEFYiSZKqhcFNkiQpJwxukiRJOWFw06Dd/XQ9tz+5rdxlSJI0YtSWuwDl13uuWgTAusveUOZKJEkaGexxkyRJygmDmyRJUk4Y3CRJknLC4CZJkpQTBjdJkqScMLhJkiTlhMFNkiQpJwxukiRJOWFwkyRJygmDmyRJUk4Y3CRJknLC4CZJkpQTZQ9uETEuIhZFxGMRsTwiPpe1nxgRCyNiVUT8NCLGZO1js+urstvnl7P+UkikcpcgSZIqUNmDG9AKnJ9SOhM4C3hdRJwLfAn4akrpZGAH8MFs+w8CO7L2r2bbVaWIclcgSZIqSdmDWyrYnV0dnX0l4HzgF1n71cCbs8sXZtfJbn9lhBFHkiRVv7IHN4CIqImIJUAdcCuwGtiZUurINtkEzMkuzwE2AmS3NwHTe3nMiyJicUQsrq+vL/VLkCRJKrmKCG4ppc6U0lnAXOAFwGlD8JhXpJQWpJQWzJw584hrlCRJKreKCG7dUko7gTuAFwFTI6I2u2kusDm7vBmYB5DdPgXYPsylHpKHF0iSpKFW9uAWETMjYmp2eTzwauAJCgHuz7PN3gtcn12+IbtOdvvtKaWKyUlDOdmucl6VJEmqBLWH3qTkZgNXR0QNhSD5s5TS/0bECuDaiPg88CjwvWz77wE/iohVQCPwjnIUXUoxpPFPkiRVi7IHt5TSUuDsXtrXUJjv1rN9H/C2YShNkiSpopR9qFSVr6sr8d171rCvvbPcpUiSNKIZ3HRIv1m6hc//9gkuv+WpcpciSdKIZnDTIe1tK/S0Ne/rOMSWkiSplAxukiRJOWFwkyRJygmDmyRJUk4Y3CRJknLC4CZJkpQTBjdJkqScMLhJkiTlhMFNkiQpJwxukiRJOWFwkyRJygmDmyRJUk4Y3CRJknLC4CZJkpQTBjdJkqScMLhJkiTlhMFNkiQpJwxukiRJOWFwkyRJygmDmyRJUk4Y3CpYKncBPaRKK0iSpBHG4FaJotwFHKjCypEkacQyuEmSJOWEwU2SJCknDG6SJEk5YXCTJEnKCYObJElSThjcJEmScsLgJkmSlBMGN0mSpJwwuEmSJOWEwU2SJCknDG6SJEk5YXCrRJ7MXZIk9cLgVsE8ubskSSpmcJMkScoJg5skSVJOGNwkSZJywuCmIXPz8md423fuJyWPrpAkqRTKHtwiYl5E3BERKyJieUR8NGv/bERsjogl2dfri+5zaUSsioinIuK15au+byMxvPyf/3mYh9btoKuXl/7ZG5ZzzcINw1+UJElVpLbcBQAdwD+llB6JiMnAwxFxa3bbV1NK/1m8cUScDrwDOAM4Dvh9RJyaUuoc1qp1WH5w/zoA/vKFx5e3EEmScqzsPW4ppa0ppUeyy83AE8Ccfu5yIXBtSqk1pbQWWAW8oPSVSpIklVfZg1uxiJgPnA0szJo+EhFLI+KqiDg6a5sDbCy62yZ6CXoRcVFELI6IxfX19SWsWpIkaXhUTHCLiEnAL4GPpZR2Ad8GTgLOArYClx/O46WUrkgpLUgpLZg5c+aQ1ytJkjTcKiK4RcRoCqHtxymlXwGklLallDpTSl3AlfxhOHQzMK/o7nOztqoz8g5vkCRJ/Sl7cIuIAL4HPJFS+kpR++yizd4CLMsu3wC8IyLGRsSJwCnAouGqd1h4ritJktSLSjiq9Dzg3cDjEbEka/sE8M6IOItCx9M64G8AUkrLI+JnwAoKR6Re7BGlkiRpJCh7cEsp3UvvfUw39nOfLwBfKFlRkiRJFajsQ6WSJEkaGIObJElSThjcJEmScsLgJkmSlBMGN0mSpJwwuEmSJOWEwU2SJCknDG45t7p+NylV1smxKq0eSZKqhcEtxx5e38grL7+LHz6wvtylAFA4e5kkSSoVg1uOrW3YC8Bjm3aWuRJJkjQcDG6SJEk5YXCTJEnKCYObJElSThjcJEmScsLgNsSqeSGMVNWvTpKkymdw0yG5yockSZXB4CZJkpQTBjdVtaaWdq5ZuMGzOUiSqoLBTWWxfvseLrvpyZIHqkt/tZRPXPc4Sza6SLEkKf8MbiqLD/1wMd+5azVrGvaU9HkadrcB0NrRVdLnkSRpOBjcVBYdnQ5dSpJ0uAxuFcxpWf17eP0OlnqeVknSCFJb7gJ0MFffGJg/+/b9AKy77A1lrkSSpOFhj5skSVJOGNw05BzhlSSpNAxu1aBCkpJDvJIklZbBLccqLShVSH6UJKlqGdw05CotUEqSVC0MbhXInitJktQbg1sFC7uuJElSEYObJElSThjcJEmScsLgJkmSlBMGN0mSpJwwuKmskofQSpI0YAY3lYdHzEqSdNgMbpIkSTlhcCsRRwAlSdJQM7hJkiTlhMFNkiQpJwxukiRJOVH24BYR8yLijohYERHLI+KjWfu0iLg1IlZm34/O2iMivh4RqyJiaUScU95XoJ6c3ydJUmmUPbgBHcA/pZROB84FLo6I04FLgNtSSqcAt2XXAS4ATsm+LgK+Pfwlqzeu8CFJUmmVPbillLamlB7JLjcDTwBzgAuBq7PNrgbenF2+EPhhKngQmBoRs4e5bEmSpGFX9uBWLCLmA2cDC4FZKaWt2U3PALOyy3OAjUV325S19XysiyJicUQsrq+vL1nNkiRJw6VigltETAJ+CXwspbSr+LaUUuIwp06llK5IKS1IKS2YOXPmEFaqXHHCnSSpilREcIuI0RRC249TSr/Kmrd1D4Fm3+uy9s3AvKK7z83aqo7n8Rw6zr+TJFWDsge3iAjge8ATKaWvFN10A/De7PJ7geuL2t+THV16LtBUNKRaFQwZkiSpN2UPbsB5wLuB8yNiSfb1euAy4NURsRJ4VXYd4EZgDbAKuBL42zLUXHHqdu3jizc9QVeX3XSSJFWr2nIXkFK6l747mV7Zy/YJuLikReXQv/xyKXc+Vc+fnDqTF580o9zlHAaDpiRJA1UJPW4aAm0dXUB+5sUN93BwTnaLJEn9MripLIYtSDlhUJJURQxuKjOTlSRJAzWkwS0iJkXE8yLimKF8XEmSJA0iuEXEKyLivyPi7B7t7wO2AYuAzRHx+aEpUZIkSTC4Hre/Bj4ArOtuiIgTgSuA8fxhMdxLI+Kgo0KVX3k58EGSpGo1mOD2AuCxlNKOorZ3U1ha5OMppeOBF1GYf+4aa1UgnIcmSVJFGExwm0nhxO7Fzgf2Ad8ESCktBu4Hzjyi6iRJkrTfYILbBKC9+0pEjAIWAItSSi1F220EZh9Zecojh1QlSSqNwQS3OuDkouvnUghz9/XYbizQgkquUnJSOKIqSVJJDSa4PQCcHRFvj4ijgE9SyA639tjuOcCWI6wvd4azt8mgJEnSyDKY4PZloAP4CbADuAB4NKV0Z/cGETGXQnBbPAQ1SkOutaOTjs6ucpchSdJhOezgllJaBLwRuAt4AvgB8IYem/0F0MTBvXCqYnma2/bsT/2Ov7xyYbnLkCTpsNQO5k4ppVvpJ5SllC4HLh9sURq8PIWnclu0rrHcJUiSdFg8V2mVyO98N5OmJEkDNZhTXo2JiGMiYlyP9kkR8fmI+E1EfCMi5g1dmao2uc2ZkiSV0WCGSj8NfAJ4CYUjTLvXcrubwoK73f+T3xIRZ6aUtg9FoZIkSSPdYIZKXwlsTik9UNT2FuAsYBmFc5leBxwHfPiIK5QkSRIwuOA2H3iqR9uFFCYr/VVK6SrgbcBWCoFOkiRJQ2AwwW0asK1H24uB9SmlxwFSSl3AQuD4IytPkiRJ3QYT3NqBKd1XIuIY4FnAvT222wtMGnxpSh5xKUmSigwmuD0NnFd0VOmfURgm7RncZlM4r6kkSZKGwGCC28+BqcDdEfEV4EtAG/Dr7g0iogY4B1g1FEWOVOGiGUfOTktJUhUZzHIgXwVeDbwCWAB0Ah9LKRX3rr2GwnDq3UdcoTQEjMCSpGpw2MEtpdQaEa+isI7bLOCRlNKaHpvtA/4BuOHIS5QkSRIM/lylCbinn9vvAO4YbFHKNw+qkCSpNAYV3IpFRADTs6uN2VIgGoHye75USZLyYdAnmY+IV0fEzcBuCuu6bQOaI+J3EfHqoSpQkiRJBYMKbhHxOeB3FA5SGE/h2L2UXX4N8LuI+OwQ1ShJkiQGEdwi4nUUTjTfQmEpkGdTCGzjs8tforD47qcj4rVDV6qqUXI6nCRJAzaYHre/o7AEyOtTSpemlFamlNqzr5UppUuBN1Dogfu7oSxW1SOcECdJ0mEbTHB7AXBfSqnPNdqy2+4BXjjYwiRJknSgwQS3ycCmAWy3JdtWKjtHZCVJ1WAwwa0OeO4AtvsjoH4Qj18VnLvVvzRcO8gRWUlSFRlMcLsTOCMiPtrXBhHxd8AfA7cPsi6NEE51kyRp4AazAO9lwNuAr0TEW4EfAmspjEY9C3gPhdNh7aNwhKkkSZKGwGDOVboiIv4C+BHwUgohrVgAzcC7U0orjrxEafjUN7fyX79/mn/90zMYUzvo9aklSSqJwZ6r9IaIOBW4CHgZMCe7aTNwF3AlQEQcn1LaMBSFSsPhs79Zzm+XbuXFJ83gDc+dXe5yJEk6wKDPVZpS2gb8e1+3R8QDwPOP5Dmk4TZsB01IkjQIpR4Lcuq5JEnSEHEST5VJrlgmSVLVKntwi4irIqIuIpYVtX02IjZHxJLs6/VFt10aEasi4inPhfoHYeemJElVr+zBDfgB8Lpe2r+aUjor+7oRICJOB94BnJHd578jombYKq1QlTYvq8LKkSSpapQ9uGXnNW0c4OYXAtemlFpTSmuBVRTOnToiVdritfb6SZJUWmUPbv34SEQszYZSj87a5gAbi7bZxB+WIjlARFwUEYsjYnF9/Yg981bFs3dOkqSBO+RSHRHxskE+9lGDvB/AtyksNZKy75cDHzicB0gpXQFcAbBgwYJcxoNqPtAgKq27UJKkHBjIGmt3wqASRAzyft1rxBUeJOJK4H+zq5uBeUWbzs3aqoqhRpIk9WYgwW0DgwxggxURs1NKW7OrbwG6jzi9AbgmIr4CHAecAiwaztpGsurt/ztYNfd2SpLy65DBLaU0v5QFRMRPgJcDMyJiE/CvwMsj4iwKWWEd8DdZLcsj4mfACqADuDil1FnK+sSAl1GuhrDjARaSpEpW9tNRpZTe2Uvz9/rZ/gvAF0pXkapK/rOkJEn7VfJRpdKQsR9NklQNDG6SJEk5YXCTJEnKCYObJElSThjcNCLct6qh3CVIknTEDG4aEb5++6pylyBJ0hEzuA2xaljLTJIkVSaDmyRJUk4Y3KReJDtOJUkVyOCmsjIfSZI0cAY3DZnDOc9npZ/JICq9QEnSiGRwkyRJygmDmyRJUk4Y3CRJknLC4FaBkoc0Dpu3fed+97ckKTcMbhXscCb7502lRKWH1u2go6tSqpEkqX8GN5VVyaNp9WZfSdIIZHCTJEnKCYNblXG61tBwP0qSKpHBrYIdzgnrXTB2iLgfJUkVzOBWgcIUJkmSemFwkyRJygmDmyRJUk4Y3CRJknLC4Kay8uBNSZIGzuCmsvDwC0mSDp/BrQpUWq+Va6BJklQaBrccq7hzmVZYOUDlpVpJko6AwU3qxc6Wdlo7OstdhiRJBzC4SUW6Ow0//etlfOAHD5W1FkmSejK4SX24b9X2cpcgSdIBDG5SEafESZIqmcFNkiQpJwxukiRJOWFw09BxnFGSpJIyuEmSJOWEwU2SJCknDG5SP/7tNyt4bOPOcpchSRJgcJP6ddV9a3nbdx4odxmSJAEGNx2GUpw83hPSS5I0cAY3HVIpzh0flXhCekrzWiVJGiplD24RcVVE1EXEsqK2aRFxa0SszL4fnbVHRHw9IlZFxNKIOKd8lUuSJA2vsgc34AfA63q0XQLcllI6Bbgtuw5wAXBK9nUR8O1hqlGHIbmgmyRJJVH24JZSuhto7NF8IXB1dvlq4M1F7T9MBQ8CUyNi9vBUqkNynFGSpJIqe3Drw6yU0tbs8jPArOzyHGBj0XabsraDRMRFEbE4IhbX19eXrtJSsuNKkiQVqdTgtl9KKTGICJNSuiKltCCltGDmzJklqKx07LiqLA79SpIqRaUGt23dQ6DZ97qsfTMwr2i7uVmbMkaModfemWjY3VruMiRJqtjgdgPw3uzye4Hri9rfkx1dei7QVDSkqhzJ2/ptf/+TR8tdgiRJ1Ja7gIj4CfByYEZEbAL+FbgM+FlEfBBYD7w92/xG4PXAKmAv8P5hL1hDquTruQ3R4+/c2z40DyRJ0hEoe3BLKb2zj5te2cu2Cbi4tBVJkiRVpkodKpXKIir1lA6SJGFwkyRJyg2D2xDL26R7SZKUHwY3aYA6uxLrt+8pdxmSpBHM4KayKnkP5WE+fuqnoP+85Sn+5Mt3srFx7xEWJUnS4BjcVBZ5PAbgwTXbAahrdjFeSVJ5GNwkSZJywuAmSZKUEwa3CuSBqZIkqTcGt0qWw3lgUJ1LolThS5Ik5ZDBrQpUSlDKac48bHc/XU9TSzv72jtp3uc5TCVJw6fs5yrV4OXxyMxK19cpr4I/BNOv3baSh9Y1snHHXjY2trDusjcMW32SpJHN4CYNwur63Wzb5bIgkqTh5VCpJElSThjcJEmScsLgJkmSlBMGN0mSpJwwuEmSJOWEwU2SJCknDG6VrEIW1i2lNBJepCRJQ8TgVoHyuq7u4USwqKBXWSlnnpAk6VAMblKRvuJkz2xn2JMklYPBTZIkKScMbtIgeJ5YSVI5GNyqTHIMr2T6OgE9wMd/sZSXf/mOYaxGkjQSeZL5KtFfqNCRO9Te/enijcNShyRpZLPHTUMuz31+ea5dklT9DG4aMvb5SZJUWgY3SZKknDC4SZIk5YTBTWUxbKe6cvxWklRFDG4asFKErZKf+sqjDSRJVcTgpkMaSUuNDPSVulyeJKkcDG7SAJjTJEmVwOCmshq2uW5DrK9OyGWbm4a3EEnSiGJwU1mUfG5bmfzwgXXlLkGSVMUMbpIkSTlhcJMGqDr7CCVJeWJw04g3kHl2hjZJUiUwuElDyGVCJEmlZHCTJEnKidpyF9CfiFgHNAOdQEdKaUFETAN+CswH1gFvTyntKFeNUk/XL9nM5HG1nH/arHKXIkmqMnnocXtFSumslNKC7PolwG0ppVOA27Lr0pDo7yQRxaOg/Q2JfvTaJXzgB4uHrCZJkrrlIbj1dCFwdXb5auDNZaylpAY6XarSplUlJ3pJklQSlR7cEnBLRDwcERdlbbNSSluzy88AvY5HRcRFEbE4IhbX19cPR61DJq+nBs1r3QNV5S9PkpQDFT3HDXhJSmlzRBwD3BoRTxbfmFJKEdFr905K6QrgCoAFCxbYBaQj0vMNVO0hVZJUmSq6xy2ltDn7XgdcB7wA2BYRswGy73Xlq1CSJGn4VGxwi4iJETG5+zLwGmAZcAPw3myz9wLXl6dC6WB27UqSSqmSh0pnAddFYUyqFrgmpfS7iHgI+FlEfBBYD7y9jDWqynhchSSpklVscEsprQHO7KV9O/DK4a9IpWBQkiRp4Cp2qFTVLY+T+wdScw5fliQpRwxuFcheqPzyRydJKiWDWwUbTO+NwaE0ev4sDNeSpHIwuFUJh+iGRh6HcCVJI4fBTZIkKScMbtIQcghVklRKBjepROqa95W7BElSlTG4acjktbdpIHUP5lyla+r3DKoeSZL6YnBTVUvDfJxtcaBbtrmJ8y67naa97cNagySpehncpCFU3Hv39dtWsnlnCw+s2V6+giRJVcXgpiGX0xHTEnKPSJKGhsFNQ8Y10CRJKi2Dm8oirwcySJJUTgY3lVWpe+niMM8p0d/WxY81kOAZdkFKkoaYwU1lVc09b6maX5wkqSwMbiqLvHVG5axcSVKVMrhVmfd//6Fyl6Be3LOynjd+4x7aO7vKXYokKccMblKJdM9xSwn+5RdLWbZ5F3XNrWWuSpKUZwa3CnY4M6RW1e0uWR06WF9DvcVnaiie4zZqf4hz3pskafAMbhXocOd/rW3YzeadLaUpRkfskQ079v98zG2SpCNhcKsCdbscfiu1I8lbv126dcjqkCSNbAY3qchQdoh1z3ErXs+tyy43SdIRMLhJJdLbfDZzmyTpSBjcqkBrx4FLTJRsAryhY7/B7mJ3oSTpSBjcKtijG3bwvH+/laa97f1u19TS/+1Hqnug739HwFytUi+061CpJOlIGNwq2Lrte9m+p42HNzSWuxQA2lw89rD0dq5Sc5sk6UgY3KSBGkh3XC/B7MD8ZnKTJA2ewa0KlbtXp9zP35ftu4d32ZTe5hp2Vei+kSTlg8GthOqbW9nX3lmyx+9tKK6cYoSeiv2pZ5r7vb34x1SpoVaSlA8GtxJ6/hd+z3uuWlTuMobUTx/aQNcQdhsNZ5B53ud/P+gg3TOSFoex1/7X3Ye47x82Tg6VSpKOgMGtxBatLd2BBX0t+1HKaPDxXz7OzxZvLOEzlNbWpn3D/pzFR/12eXyHJOkIGNxy4IYlW3ptb9zTNsyVFPRcfuTBNdvLUkel6x7K3t3asb/NHjdJ0pEwuOXAPSsbem0v13ypuuYDJ/n/581PlaeQYTSYXd3rwQkD7HF7elszzftKuz6fJCl/DG45Vq5jE75379ryPHEFOZzQ3Fk0J3CgC/C+5qt38+7vVdf8SEnDY23DHuZf8lvufrq+3KWoBAxuOdDXv/q+clvJTnnV1/MN67OVVqmP1D2cMycs2bjziJ5rw/a9tLtosjTiPLSuMLf6+j6m2QynXfva+d2yZ8pdRlUxuOVANS6y0Z1fdu4tzzy9UimOZbv2dRx0e28H5G7Yvpelm3Ye1qnLOjq7OOffb+W6Rzf1entd8z5e9uU7+MJvnxjwY0qqDpX0P+OjP3mUD//Pw2xs3FvuUqqGwS3HKmUdt8H08D21rbD22QevXnzEz99fz9RADgb4yysfHNDzbBqCPzy99bi97Mt38KZv3se5//e2fu/b2ZWob27lE9c9TuOeNhr3tPEPP32Mxzc1HbTtjj2FEHjfqgPnR7Z1dHHZTU86f04aASrhYKiNO1oASrqm6UhjcMuBw/3VG+5f1SN5vpYh+GXe0c/RtQPJlI9s+EPwu+7Rzb1u88TWXWwZwFIih4rSi9Y2cuqnbuKB1dv58cL1zL/kt/tva2nv5Eu/e7LPo4Xf9p37ef4Xfs81CzccsCTL129fedC23X+we2b7Xz+6me/ctZrLb3n6kK9Fg5NSGvbpClKx/R/qK+htWEGl5J7BbRh0HOE8o97CQFdX4rKbnjzkfTc27qWlbXg+6XSHsNuf3DYsz9etv0+VPW850p/FofQ2PFrsyzc/RVtHF++88kG+e8/BB3l8+87VfPrXyw5qX9uw54CAWfwybl3xh/29sXEv+9o79wfWnmezaM8Oa23t6GLJxp3c28cRyxq8v7xyISdeemO5y1DmRw+s4//eePhTBrq6EvesrM9lCK+MsZiC7lpyuBsrlsFtGJz8yZuO6P69vd+Xb9k1oN6ql/7HHXzoh0c+HNmfRzfs5Kx/u2X/9X/46WMlfb6elm/exdamll5v6/lHt7ewNJR+/8TAQ2tfByqsrt+9//LtT25jycadvOI/7zxgm6/+/sAes3tW1tPe2cVL/+MOPvCDh/b/kXxm1z5+u3Qrtz2xjaWbDhxSfvO37uOvvrcQKAyp/uaxAycy3/FUHfMv+S1Newc+rPrrRzf3Gjx72ti4l/dcteiANe6KrWvYwyv+807qm4f3/LJD4QHXNTzAb5duLetc1k9fv5wr7l5zyO0272zhvMtuZ9OOwpSIH9y/jnd/bxE3L8/vxAP24dMAABpeSURBVPpKyEqHO6Onqyuxt63/D8AjncEtBxr3tNHWcWBPUedhfHy5d1Xpe1V2HsY/96F2+a1P86Iv3g7A+u17+MR1j+9fgqPnXmocon8gPdeyG4z123ufM/dk0blPP/CDxbz5W/cd8rHe/b1FbMjm4N2/ejv3ry78zJta2rn4mkf44NWLedM3//A4P1m0Yf/lVXW7edd3F/J3P3mUxj1tdHYlmva28/7vPwTAiq27DniuppZ2vnn7StY17Dmojo/9dAk/enD9Ieu9/JanuPvpem5dUfinuHxLEz9euH7/5Y/85BHWNuzhpmVb+3yM3a0drG3YQ9Pedr51xyp29TFv766n6w/rwI/hllLiyWd28d171hzUA3rDY1u4Z+XglnTY29ZR8td9qMfftGMvF1/zCB/+n4e5efkzB32QWtewhzVFH1QG638eXM+rvnLXET3GLxZvYvPOFn72UGEaQvfv05adw3+2lSO1f6S0grq5Bjrf7nO/Wc7pn7nZI+L7UVvuAgYrIl4HfA2oAb6bUrqszCX1a9OOvcw9ekK/26xr2MMHr36I1fUH/0M89VM3ccEfHct//PlzmTxuNKvq+v5j1/272vOXtqsrsbutg89ev5yLzz+Zk2ZO6ree1o5OPv6LpZw44+Dt1vbyT/vgOlKvB1BcWxQaevOOKx7grefM5e0L5h3yOXr66LVLWLJxJ392zlyed8LRvdZ0OLXmySsv/8M/rs/3cTTprx45eA7fO674w8EZ5/z7rQfd/s4rH+Qrbz+TE6ZP5N/+dwWPZQeD/OctT/PaM2bxtXeczcptu/mvol7AtQ17WNuwm2cfexRzpo6ntaOTul2tzJs2gctuepJfZ8sUXLtoI285ey5v+Pq9AHzyugN761Zu282yzU1saNzL6JpRrKxr5m9ffjJdXYm3/vd9PL3tD78HGxv38q4XnsBvlm7h0gtOY/ueNv7hp0u4Z2UDLz5pOtd86Nz9237l1qeZNmE07zvvxP1tzfvamTxuNPvaOxlbO4quBCd94kbef9583vXC45l11Dguv+Vp3vXC45kxaSxdKTF90the9zMU5kWeduzkA95Xj27YwQnTJzJt4pj9bT9bvJGP//Lx/dfXXfYGoNDj+fc/efSAtmL3rWpg4thaduxp4xWnHbO/fdnmJt74jXv3X3/q869jbG1Nn3UO1q0rtvGhHy7m5x9+Ec+fP63XbVqzD5wPrmnkwTWN/NuFZzCmZhRvXzCPPW0dvDzrSe7t9R2OT2W9vO2dXXz618v4yPknM/foCdQ1Hxi6tja1UDtqFDMnH/xz6/4xdR/53R0c2ju76OxK1IzKx9+H3y7dyoothQ9be4Zpmkx/in9HB+LnDxeOlG/t6GJ0jX1LvcllcIuIGuBbwKuBTcBDEXFDSmlFuWq64bEtbN7Rwp+dM6fX21/ypTv4twvP4DPXL2fxp17F9IljDgoKL+8xHNbTTcue4dxnTee9L57PP/+8/+HIul0H/sG68u41fKFonsfyLbu4+R9eRlNLO2d+7ha+/77nH/DHv6mlnY9e+yh3PtX7p/1rFh66V+XES2886B/mph17ueRXjx+w3eadLcyZOh6A+1c37P8j//YF8/jWHat45XOOYf70iazYuou5U8fTuLeN04496qDn27yzhe6/resa9nD2vKnsbT3wD9eDaxr5mx8dPHTc3NrBUeNGH/I15d3D63cc1Naw+9C9h//4s97fbzcv38Zpn/7dQe09h3b7snBtI+df3ve2P3pw/UE9eM+aMYl/vWEZ23YdWPe1D23k2qy3pOfQ2P2rt3PhN+/lgj+ezZlzp/L12woHdBxz1DjG1o7ixws3cPuTdQfc5z/+/LkAfP++dXz/vnVFz7OBfe2Ff+pvOXtOnwe0XPC1ezhz7hSeP38an3rj6Xzs2kf3B9Z/eNWpzJg8hpa2Tu7qsUjq/asbePFJM/b3eAJ87fcreecL57F++16uX7KZFVt2HTDnceUXLuC+VQ007mk76Gf1vqse4poPvZAbH3+GP54zhWd27eOseVO57tFNLJg/jZNmTtr/gab4b1JnV2JUwL72Ljbv3MvJx0w+4HEfWF0YEv74L5byzb88h2Vbmvj9im1c8Z4F+7fpOb/2M9cvBzjob0BKic6uxMXXPMInX386x08vfMhdVbebtQ17eGLrLv7u/JMPqG9V3W6+cftK/u1Nf7S/beGaxv3vgx+8//m8r2gfFh8I9JuPvIQtTS2ccswknpV9gO3+2/HkM7u4Z2U9P15Y+ID5xZue5Is3Pclz507hxBkT+a+/OGvAH/IadrcybnQNk8b2/a+2sysRwKh+guHtT27jxBmTOGbyWMaPruHBtdv54zlT+NsfP8Jn3ng6e9o6ee6cKYwaFVx8zSP773frim37Rx+6g+eyzU08tK6R9593Ihsb99Kwu5Wzjz/4Q+5Q6/7MvKZ+N3XNrZz7rOlA4T0yuiaorRlFe2cXe7P3TGdvaydlFq1t5LTZk0fE3+zeRCV1pQ5URLwI+GxK6bXZ9UsBUkpf7G37BQsWpMWLSzfP675VDbzruwtL9viSJJXL+NE1Q7ICQH+eM/sonugxLWMgzjjuKJZvOfz7ja0dxdjaUfsPKDt99lGMrgke67G80p+eeRy/eWwL86dPYF02veW2f/qTQ45YHamIeDiltKC32/LaDzkH2Fh0fVPWVhbdnxwkSao2pQ5twKBCGzCo0AaFodjiVQBWbN11UGgD9h+0ta5oTnLxtJRyyOVQ6UBExEXARQDHH398SZ+rZlSw7rI30NrRySW/fJzrl2zmlGMmE1GYH7G7tYNdLR38yakz2byzhakTRlM7Kti1r4OH1+9gztTxTBhTw6gIakYFaxv28LJTZzDrqHFcu2gjbz1nDjcte4Z3vuB4fr54I1MmjGbyuNGMHz2KMbU11O3aR1dKTBpbS1cqHK3YlRLTJo5lxZZdPGvGRNq7unjO7KNobe9i2eYmnq5rZkzNKF7x7GPYuGMvMyeP5cE129nX3sWpsyaxfXcb5540nSe27mLyuNGcMG0CdzxVx3FTxlNbEyzfsovXnD6LrpTY3drB1PFj2Na8j5mTxnJLtjzFq54zi6aWNiaNrd3f/T2mdhSr6nazfU8b0yaMob2zi5pRwb72Ts591nRqa4I19Xv2T9B/69lzuG91AydMm0j97la2NrXwlrPn0t7Zxcq63ZwwbQJrGnYzdfwY2jq6WN+4hwUnTGP6pDH8ZNEG2jsTp86axL72LiaMqaG+uZVnHzuZ5Vt2kVLi1FmTWbx+B6cdO5maUUFKhRrPOO4ofvHwJs4+fipnzp3KrSu2cfz0CexqaWdUBJPG1XLnU/WcOW8qf3LKDJ7a1kzNqKCzKzFxTC31u1tZtLaR1/3RsTywejtvPWcu40aP4tYV23ju3Cms2NrMhNE1dHR1cdqxRzF/xkTuXVnP1qZ9nHHcFDq7upg6YQwr65o5atxontrWzIVnzmHh2u3MmTqeOUePp3lfB3OPHk9dcys1ETz5zC7G1tbQuKeNU2dN4kUnzWD5libWbd/LHU/W8arnHMPdKxt40UnTeWLLLs6YM4V1DXto2N3K1qZ9/NW5xzN94ljuXdVAe2cX86dPLLw/jx7PKcdMoq65lZmTx7KuYQ8dnYnWjk6e3rabKeNHc+qxk5k8rpbpE8dw36oGJo2tZdSo4NFsOO/MeVM55ZhJbG1q4YmtzRw9YTTTJ41la1MLR40bzbSJYzhm8jgeWF2Yt3XMUWO5b1VhKO6lp8zgkfU7mDi2lhNnTGR0zShW1+9ma9M+zjt5Omvq9zBj0lhqRgWPb25i8rhaRtcUfob1za0cPWEMi9Y2UjMqOO/k6Ty2qYlJY2vZ2tTCvvYujp4wOnvvjWL99j0s3dTEcVPGsbu1gzPnTWXyuFqa93Wwa18HU8eP5q6n63npKTNo6+hixdZdtLR1ctLMSUyZMJpFaxsZFTBt4ljmTB3HY5uaeM3ps2jY3cr2PW1MGT+aLTv3MbZ2FJt3tvCc2Uext62DmZPGsnj9Dp41YyLPnTuFvW2ddCXY0LiHU46ZzM3Ln+G8k2ewr72TrpR4aF1hyPu8k6czY9JY1tQXfo6Ne9o4YfoE1jXs5dgp42hqaWfetPGs376XV58+i7lHT2DTjr08umEn0yeOob0rseCEo3lkww7Gj66hKyUeXNOY/f4ew6YdLTS1tHPijImkBB1dhffF75/Ytn/e1+wp49nT1sH40TU07+tg6oTRzJ8xERJs3LGXqRPGkFLinpUNPH/+0WxsbOGZXft48UnTWV2/m9pRo2hp72Tu0ePZ1dLO3rZOzj/tGFbX76a9MzFu9CjGj66hoytRO6owpLamfjejawo9Jsu37OKP505hyvjRNOxu5cQZk3hk/Q4272xh8rha2jq6eP78aWzbtY99HZ1sbGzhj+dMAQp/nxt2t/Kik2bQ0tbBA6u3c8qsydQ3t/KaM2bx/fvWcd7J09m2q5Vxo0exsbGFaRPHcNLMiTTv62B3awezp4xn8fpG5k+fyORxtRwzeRyr6po5dso4Zk8ZT1NLO3c+VRiGf94J0xg7ehSt7Z1MHFvLw+t30LinjeedcDT3rGzgeScczYbGvexp7eDMuVNpae9ky84W2ju7+KM5U3jqmWbOP+0Y7l3VQEowaWwtq+p309mVeONzZxMRTB0/mt2tHVz36GaOPWocO/a2cd7JMxg/uoZRo4KulKjbtY+IYGtTCyfPnMSGxr1MHFvLvvZOTpg+ka6uxM6Wdk6dNYmG3W3My+YLnnfyDO58qo6aUcGxR43noXWNTB5Xy/wZE0kp0dLWyenHHcVdT9dz/LQJ1De3sW77HmZOGpu97i72dXRy1LjR+/dnw+5WTp01mXOOn8qmHS2srNvNSTMncvy0CTS1tLN9TxsTxtTwyIadTB0/mhefNJ265lZSKizk/qKTpnPrim1MHFPDlAljmDJ+NDv3ttHa3rX/d2xlXTN/+tzjmDZxDHXNrezc28bUCWPoSolxtaOorRnFnKnjScCDa7bTlQoHaJ08axKjIvYvsfTkM7vo6Ex85e1nlTRTHIpDpZIkSRWkGodKHwJOiYgTI2IM8A7ghjLXJEmSVFK5HCpNKXVExEeAmyksB3JVSml5mcuSJEkqqVwGN4CU0o2A55WRJEkjRl6HSiVJkkYcg5skSVJOGNwkSZJywuAmSZKUEwY3SZKknDC4SZIk5YTBTZIkKScMbpIkSTlhcJMkScoJg5skSVJOGNwkSZJywuAmSZKUE5FSKncNJRcR9cD6YXiqGUDDMDxPnrhPeud+6Z375WDuk965X3rnfuld3vbLCSmlmb3dMCKC23CJiMUppQXlrqOSuE96537pnfvlYO6T3rlfeud+6V017ReHSiVJknLC4CZJkpQTBrehdUW5C6hA7pPeuV965345mPukd+6X3rlfelc1+8U5bpIkSTlhj5skSVJOGNwkSZJywuA2BCLidRHxVESsiohLyl1PKUXEvIi4IyJWRMTyiPho1v7ZiNgcEUuyr9cX3efSbN88FRGvLWqvqv0WEesi4vHs9S/O2qZFxK0RsTL7fnTWHhHx9ey1L42Ic4oe573Z9isj4r3lej1DISKeXfSeWBIRuyLiYyPx/RIRV0VEXUQsK2obsvdHRDwve/+tyu4bw/sKD18f++TLEfFk9rqvi4ipWfv8iGgpes98p+g+vb72vvZvpetjvwzZ70xEnBgRC7P2n0bEmOF7dYPXx375adE+WRcRS7L26n2/pJT8OoIvoAZYDTwLGAM8Bpxe7rpK+HpnA+dklycDTwOnA58F/rmX7U/P9slY4MRsX9VU434D1gEzerT9B3BJdvkS4EvZ5dcDNwEBnAsszNqnAWuy70dnl48u92sbov1TAzwDnDAS3y/Ay4BzgGWleH8Ai7JtI7vvBeV+zYPcJ68BarPLXyraJ/OLt+vxOL2+9r72b6V/9bFfhux3BvgZ8I7s8neA/1Pu1zzY/dLj9suBz1T7+8UetyP3AmBVSmlNSqkNuBa4sMw1lUxKaWtK6ZHscjPwBDCnn7tcCFybUmpNKa0FVlHYZyNlv10IXJ1dvhp4c1H7D1PBg8DUiJgNvBa4NaXUmFLaAdwKvG64iy6RVwKrU0r9ncWkat8vKaW7gcYezUPy/shuOyql9GAq/Nf5YdFjVaze9klK6ZaUUkd29UFgbn+PcYjX3tf+rWh9vFf6cli/M1nv0vnAL7L7V8V+yV7X24Gf9PcY1fB+MbgduTnAxqLrm+g/yFSNiJgPnA0szJo+kg1vXFXUxdzX/qnG/ZaAWyLi4Yi4KGublVLaml1+BpiVXR5J+6XbOzjwj+pIf7/A0L0/5mSXe7bn3Qco9Ih0OzEiHo2IuyLipVlbf6+9r/2bV0PxOzMd2FkUjqvlvfJSYFtKaWVRW1W+XwxuGpSImAT8EvhYSmkX8G3gJOAsYCuFLuuR5iUppXOAC4CLI+JlxTdmn+5G5Po72RyaNwE/z5p8v/Qwkt8fvYmITwIdwI+zpq3A8Smls4F/BK6JiKMG+nhVsH/9nenfOznwg2HVvl8MbkduMzCv6PrcrK1qRcRoCqHtxymlXwGklLallDpTSl3AlRS66aHv/VN1+y2ltDn7XgdcR2EfbMu65ru76OuyzUfMfslcADySUtoGvl+KDNX7YzMHDinmev9ExPuANwLvyv6Bkg0Fbs8uP0xh/tap9P/a+9q/uTOEvzPbKQy91/Zoz63stbwV+Gl3WzW/XwxuR+4h4JTsKJ0xFIaDbihzTSWTzSP4HvBESukrRe2zizZ7C9B91M8NwDsiYmxEnAicQmFiaFXtt4iYGBGTuy9TmGC9jMJr6j7y773A9dnlG4D3RMG5QFPWRX8z8JqIODobCnlN1pZ3B3waHunvlyJD8v7IbtsVEedmv6PvKXqsXImI1wH/ArwppbS3qH1mRNRkl59F4b2x5hCvva/9mztD9TuTBeE7gD/P7p/r/ZJ5FfBkSmn/EGhVv1/KfXRENXxROALsaQqJ/pPlrqfEr/UlFLqPlwJLsq/XAz8CHs/abwBmF93nk9m+eYqiI92qab9ROHLrsexreffroTCf5DZgJfB7YFrWHsC3stf+OLCg6LE+QGGC8Srg/eV+bUOwbyZS+JQ/pahtxL1fKATXrUA7hXk1HxzK9wewgMI/89XAN8nOjFPJX33sk1UU5mZ1/335Trbtn2W/W0uAR4A/PdRr72v/VvpXH/tlyH5nsr9Xi7J9/XNgbLlf82D3S9b+A+DDPbat2veLp7ySJEnKCYdKJUmScsLgJkmSlBMGN0mSpJwwuEmSJOWEwU2SJCknDG6SciEi1kVEGsDXy8td60BExGezej9b7lok5UftoTeRpIpyM4XzCPalv9skKdcMbpLy5rKU0p3lLkKSysGhUkmSpJwwuEmqShExP5tDti4iaiPikoh4IiL2RcS2iLg6Io7v5/5nRMQPI2JjRLRGRENE3BgRFxzieV8bEb+KiC0R0RYRz0TEfRHx8YgY38d9ZkXE/4uITdlzrY2IyyJiXC/b1kTEhyPi/ohoyp5jW0Q8EhGXR8TMw99bkvLC4CZpJPgp8DlgA/BroJXCyaUfiohn99w4It4EPAy8G2gCfgmsAF4L3BgR/97LfSIivg38jsJJwDdn93sMmAdcBszqpbZ52XO9EXgAuBM4Bvg48LNetv8e8G3gLGAh8IvsOaYA/wicdIh9ISnHnOMmqdqdAIwHzk4prQCIiDEUAtBfUTh59wu6N46IY7O2scA/pZS+UnTby4HfAp+KiHtTSjcXPc9HgQ8D24A3p5QeLLpfAK8AdvRS3weA7wIXp5Tasu2fQ+Ek4H8aEeellO7L2k8A3kvhJOzPTyltK36giDgL2HJYe0dSrtjjJilv7uhnKZCdfdzn37tDG0AWkP4O2AU8PyLOK9r2Q8BRwH3FoS27353AN7Kr/9zdHhG1wCezq+8rDm3Z/VJK6faUUlMvtW0E/r47tGXbP0EhPAK8smjbY7Lvj/QMbdn9lqSU6np5DklVwh43SXnT33Ige/to/5+eDSmlnRHxG+BdwMuB+7Kb/iT7fnUfj3UVhWHMl0RETUqpE1gAzAA2pZR+d8hXcKDbU0otvbQ/mX0/rkdbM/CGiPgE8OOU0vrDfD5JOWZwk5Q3h7scyM6UUl89ceuy73OL2uZk39f2c58uYBwwHaijMBwL8NRh1NVtQx/tu7Lv+w9QSCk1R8QHKITHLwBfiIjNFObG/Ra4NqW0bxA1SMoJh0olqXepRNv21HU4G6eUfgEcD7yPQoDbDfw58H3gyYiYdwS1SKpwBjdJ1W5qREzp47b52ffNRW3dl5/Vz31GAfuAxqytu9fsoCNUSyGltDOldHVK6YMppdOAk4E7KPT8fWk4apBUHgY3SSPBu3o2ZGHujdnVO4tuuiv7/p4+Huv92fd7U0od2eWHgQZgbkS89shKPXwppdUUhk4Bzhzu55c0fAxukkaCz2RLbAAQEaOBr1FY++zhlNK9RdteSeEAgJdExN8XP0hEvIzC0agAl3e3p5TagS9mV78fES/ocb+IiFf00/M3IBFxdkT8RR8L+f5p9t2DFaQq5sEJkvLmkoh4Xz+3X5NSuqXo+gYKPWJLIuJ2CgvqvpjCwrcN9OhZSyk9ExHvprBo79ci4q+BZRSO7nwphQ+8n+/l6NGvAs8B/hp4MCIWA6uAacDp2fOdmD3/YJ0AXAvsjYhHKCwlMgY4m8LQbjPwmSN4fEkVzuAmKW8ONRS5BCgObgl4O3AJhTMhnEDhiM3/AT6dUlrX8wFSStdHxAIKy36cT2Hyf3P2uN9IKd3Yy30S8KGIuJ7CQrwvoHB2g+0UAtw36HsZk4F6ELiUwpIlpwHPA9ooBLjLs9rscZOqWBT+1khSdYmI+RSW9FifUppf1mIkaYg4x02SJCknDG6SJEk5YXCTJEnKCee4SZIk5YQ9bpIkSTlhcJMkScoJg5skSVJOGNwkSZJywuAmSZKUE/8/em7rZAqsfqEAAAAASUVORK5CYII=\n","text/plain":["<Figure size 720x504 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"6HqyLqciA306","executionInfo":{"status":"ok","timestamp":1617432443390,"user_tz":-540,"elapsed":614,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}}},"source":["def test_model(model, mode='random', display=True):\n","  # 모델을 테스트하는 함수를 만든다. (게임만 돌리고 학습은 안한다.)\n","    i = 0\n","    test_game = Gridworld(mode=mode)\n","    state_ = test_game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n","    state = torch.from_numpy(state_).float()\n","    if display:\n","        print(\"Initial State:\")\n","        print(test_game.display())\n","    status = 1\n","    while(status == 1): #A\n","        qval = model(state)\n","        qval_ = qval.data.numpy()\n","        # 각각의 행동들의 기대가치가 담긴 리스트를 qval_에 담는다.\n","        action_ = np.argmax(qval_) #B\n","        # 그리고 기대가치가 가장 높은 행동의 인덱스를 추출한다.\n","        action = action_set[action_]\n","        # 해당 인덱스를 문자열로 변환해준다.\n","        if display:\n","            print('Move #: %s; Taking action: %s' % (i, action))\n","        test_game.makeMove(action)\n","        # 움직이기\n","        state_ = test_game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n","        # 그 다음 환경 세팅\n","        state = torch.from_numpy(state_).float()\n","        # 환경을 토치가 인식할 수 있도록 .float() 변환\n","        if display:\n","            print(test_game.display())\n","        reward = test_game.reward()\n","        # 행동 했으니 보상을 담는다.\n","        if reward != -1:\n","            if reward > 0:\n","                status = 2\n","                if display:\n","                    print(\"Game won! Reward: %s\" % (reward,))\n","            else:\n","                status = 0\n","                if display:\n","                    print(\"Game LOST. Reward: %s\" % (reward,))\n","        i += 1\n","        if (i > 15):\n","            if display:\n","                print(\"Game lost; too many moves.\")\n","            break\n","    # status 가 바뀔때까지 계속 while 돌아간다.\n","    # 그리고 test_model 은 state1, state2 따로 저장하지 않는다.\n","    # 손실을 구할 필요도 없고, 단순히 이동만 하면 되기 때문이다.\n","\n","    win = True if status == 2 else False\n","    return win"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxW5c9Q6BAWz","executionInfo":{"status":"ok","timestamp":1616401169264,"user_tz":-540,"elapsed":523,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"1d5db347-5ac9-40ea-8761-e733004c7e7d"},"source":["# 신경망을 테스트하는 함수\n","test_model(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Initial State:\n","[['+' '-' 'P' ' ']\n"," [' ' 'W' ' ' ' ']\n"," [' ' ' ' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 0; Taking action: d\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' 'P' ' ']\n"," [' ' ' ' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 1; Taking action: d\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' ' ' ' ']\n"," [' ' ' ' 'P' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 2; Taking action: l\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' ' ' ' ']\n"," [' ' 'P' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 3; Taking action: l\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' ' ' ' ']\n"," ['P' ' ' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 4; Taking action: u\n","[['+' '-' ' ' ' ']\n"," ['P' 'W' ' ' ' ']\n"," [' ' ' ' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 5; Taking action: u\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' ' ' ' ']\n"," [' ' ' ' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Game won! Reward: 10\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"r-7AkqWKBCan"},"source":["# 하지만 위의 경우는 패턴이 같은 게임은 학습할 수 있지만,\n","# 패턴이 바뀌는 게임의 경우엔 학습이 이루어지지 않는다.\n","# 오른쪽으로 이동했을 때 보상을 받던게,\n","# 지형이 바뀌면 오른쪽으로 똑같게 이동했는데 패널티를 받는 경우가 생긴다.\n","# 그 경우 모델이 학습한 것을 다시 되돌리게 되고,\n","# 결국엔 전체적으로 학습이 이루어지지 않는다.\n","\n","# 이를 파국적 망각(Catastrophic forgetting) 이라고 한다.\n","# 이를 해결하기 위해서는 한판 한판의 데이터를 학습하지 말고,\n","# 여러 판들(batch size - 대략 200개 이상)의 데이터를 모아서,\n","# 그중에서 랜덤하게 뽑아 적당한 부분집합 (대충 30개)를 뽑아서,\n","# 이 30개 부분집합 전체에 대한 합 또는 평균 기울기를 계산 하고,\n","# 이를 한꺼번에 학습(가중치들을 갱신)시키는 것이다.\n","\n","# 따라서, 랜덤한 경우를 해결하기 위한 방법으로 경험재현(Experience replay) 기법이 존재한다.\n","\n","# 기존의 온라인 학습(한번 한번 학습)에 배치 훈련 방식(부분집합으로 훈련)을 도입하는 것이다.\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_pxhZXScrWQv","executionInfo":{"status":"ok","timestamp":1617432446519,"user_tz":-540,"elapsed":598,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}}},"source":["# 인공신경망 만들기\n","l1 = 64\n","l2 = 150\n","l3 = 100\n","l4 = 4\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(l1, l2),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(l2, l3),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(l3,l4)\n",")\n","\n","loss_fn = torch.nn.MSELoss()\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","gamma = 0.9\n","epsilon = 1.0\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","gamma = 0.9\n","epsilon = 1.0\n","\n","action_set = {\n","    0: 'u',\n","    1: 'd',\n","    2: 'l',\n","    3: 'r',\n","}"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"yuQmJ0IS6XEJ","executionInfo":{"status":"ok","timestamp":1617432446889,"user_tz":-540,"elapsed":561,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}}},"source":["# 이제 경험재현기법을 적용한다.\n","from collections import deque\n","import numpy as np"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"717lDm0en0-M"},"source":["\n","epochs = 5000\n","losses = []\n","mem_size = 1000 # 기억을 담을 수 있는 최대 공간. (뇌용량)\n","batch_size = 200 # 그 기억중에서 몇개를 주기적으로 학습할 것이냐.\n","replay = deque(maxlen = mem_size) # deque 는 왜 쓰는거지?\n","max_moves = 50 # 50회 이상 움직이면 게임 종료.\n","h = 0 # 이건 또 뭐지?\n","\n","for i in range(epochs): # 5000번까지 게임을 돌린다.\n","  game = Gridworld(size=4, mode='random')\n","  # 4*4 사이즈 게임판 만들어주고\n","  state1_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/100.0\n","  # 상태 ndarray 형태로 담아주고\n","  state1 = torch.from_numpy(state1_).float()\n","  # torch 가 인식할 수 있도록 torch 전용 데이터로 변환(.float())\n","  status = 1\n","  # 이제 게임 시작!\n","  mov=0 # 움직임 수 초기화\n","\n","  while(status==1):\n","    mov+=1 \n","    qval = model(state1)\n","    qval_ = qval.data.numpy()\n","    # 파이토치에 있는 값을 ndarray 로 다시 변환한다.\n","    if (random.random()<epsilon):\n","      action_ = np.random.randint(0,4)\n","    else:\n","      action_ = np.argmax(qval_)\n","    # 입실론을 통해 무작위 행동을 할지, 최적의 선택을 할지 설정한다.\n","    action = action_set[action_]\n","    game.makeMove(action)\n","    state2_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/100.0\n","    state2 = torch.from_numpy(state2_).float()\n","    reward = game.reward()\n","    done = True if reward>0 else False\n","    exp = (state1, action_, reward, state2, done)\n","    replay.append(exp)\n","    state1 = state2\n","\n","    if len(replay)>batch_size:\n","      minibatch = random.sample(replay, batch_size)\n","      # 미니배치를 랜덤하게 뽑는다.\n","      state1_batch = torch.cat([s1 for (s1,a,r,s2,d) in minibatch])\n","      action_batch = torch.Tensor([a for (s1,a,r,s2,d) in minibatch])\n","      reward_batch = torch.Tensor([r for (s1,a,r,s2,d) in minibatch])\n","      state2_batch = torch.cat([s2 for (s1,a,r,s2,d) in minibatch])\n","      done_batch = torch.Tensor([d for (s1,a,r,s2,d) in minibatch])\n","\n","      Q1 = model(state1_batch)\n","      with torch.no_grad():\n","        Q2 = model(state2_batch)\n","      \n","      Y = reward_batch + gamma*((1-done_batch)*torch.max(Q2, dim=1)[0])\n","      # 상태2 에서의 기대보상\n","      X = Q1.gather(dim=1, index=action_batch.long().unsqueeze(dim=1)).squeeze()\n","      # 상태1 에서의 기대보상\n","\n","      loss = loss_fn(X, Y.detach())\n","      optimizer.zero_grad()\n","      # 최적화기 리셋\n","\n","      loss.backward()\n","      # 손실로 역전파\n","      losses.append(loss.item())\n","      # 손실을 losses 리스트에 담아준다.\n","      optimizer.step()\n","      # optimizer 진화시키기\n","\n","    if reward != -1 or mov>max_moves:\n","      # 판이 끝났거나 게임횟수가 50번 넘어가는 경우\n","      status = 0\n","      mov = 0\n","\n","losses = np.array(losses)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGGLdRGK7GKR","executionInfo":{"status":"ok","timestamp":1617189095484,"user_tz":-540,"elapsed":2566,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"caa41169-d5bb-4da5-953b-232f802d584b"},"source":["max_games = 1000\n","wins = 0\n","for i in range(max_games):\n","  win = test_model(model, mode='random', display=False)\n","  if win:\n","    wins += 1\n","win_perc = float(wins)/float(max_games)\n","print(\"Games played: {0}, # of wins: {1}\".format(max_games, wins))\n","print(\"Win percentage: {}\".format(win_perc))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Games played: 1000, # of wins: 484\n","Win percentage: 0.484\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZMkeR_hx6ccC","executionInfo":{"status":"ok","timestamp":1617432451641,"user_tz":-540,"elapsed":569,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}}},"source":["import copy\n","# 정책망을 만들기 위해 신경망을 복사할 때 쓸 것."],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulobXs4s-z3X","executionInfo":{"status":"ok","timestamp":1617432453043,"user_tz":-540,"elapsed":701,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}}},"source":["model = torch.nn.Sequential(\n","    torch.nn.Linear(l1,l2)\n","    , torch.nn.ReLU()\n","    , torch.nn.Linear(l2,l3)\n","    , torch.nn.ReLU()\n","    , torch.nn.Linear(l3,l4)\n",")\n","\n","model2 = copy.deepcopy(model)\n","# 주 Q 신경망을 그대로 복제해서 목표망을 만든다.\n","model2.load_state_dict(model.state_dict())\n","# 주 Q 신경망의 매개변수들을 복사한다.\n","\n","loss_fn = torch.nn.MSELoss()\n","# 손실함수를 규정해주고,\n","learning_rate = 1e-3\n","# 학습율을 0.001 로 맞춰주고,\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 초기화 과정\n","\n","gamma = 0.9\n","epsilon = 1.0\n","\n","action_set = {\n","    0: 'u',\n","    1: 'd',\n","    2: 'l',\n","    3: 'r',\n","}"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"llC-fD9TAqol","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617436899873,"user_tz":-540,"elapsed":4088006,"user":{"displayName":"Smile Yoon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWVkwvBjx-rXtD608FD95Ze8M_7r_2Lohh5ZquO4=s64","userId":"08492174067066637630"}},"outputId":"0df14267-cc02-4e5c-87ae-cdb8880936cf"},"source":["from collections import deque\n","epochs = 5000\n","losses = []\n","mem_size = 1000\n","batch_size = 200\n","replay = deque(maxlen = mem_size)\n","max_moves = 50\n","h = 0\n","sync_freq = 500\n","j=0\n","\n","for i in range(epochs):\n","  game = Gridworld(size=4, mode='random')\n","  state1_ = game.board.render_np().reshape(1,64)+np.random.rand(1,64)/100.0\n","  state1 = torch.from_numpy(state1_).float()\n","  status=1\n","  mov=0\n","  # 게임판을 만들고, 초기 상태를 지정한다.\n","\n","  while(status==1):\n","    j += 1\n","    mov += 1\n","    qval = model(state1)\n","    # 현재 상태에서 각 움직임의 기대가치를 가져온다.\n","    qval_ = qval.data.numpy()\n","    # 기대가치들의 리스트를 numpy 로 변환해준다.\n","\n","    if (random.random() < epsilon):\n","      # epsilon의 확률로 랜덤동작을 수행한다.\n","      action_ = np.random.randint(0,4)\n","    else:\n","      # 랜덤동작이 아닐 경우 최선의 선택을 고른다. \n","      action_ = np.argmax(qval_)\n","\n","    action = action_set[action_]\n","    state2_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/100.0\n","    state2 = torch.from_numpy(state2_).float()\n","    reward = game.reward()\n","    \n","    done = True if reward > 0 else False\n","    # reward > 0 이면 게임이 끝났음을 저장한다.\n","    exp = (state1, action_, reward, state2, done)\n","    replay.append(exp)\n","    state1 = state2\n","\n","    if len(replay) > batch_size:\n","      # 경험재현 리스트에 해당 배치 이상이 쌓이면\n","      # 경험재현기법을 시작한다.\n","      minibatch = random.sample(replay, batch_size)\n","      # 경험리스트에 배치사이즈만큼 샘플을 뽑아 minibatch 에 담는다.\n","      state1_batch = torch.cat([s1 for (s1,a,r,s2,d) in minibatch])\n","      action_batch = torch.Tensor([a for (s1,a,r,s2,d) in minibatch])\n","      reward_batch = torch.Tensor([r for (s1,a,r,s2,d) in minibatch])\n","      state2_batch = torch.cat([s2 for (s1,a,r,s2,d) in minibatch])\n","      done_batch = torch.Tensor([d for (s1,a,r,s2,d) in minibatch])\n","\n","      Q1 = model(state1_batch)\n","      with torch.no_grad():\n","        Q2 = model(state2_batch)\n","        # 상태2 에서의 기대치들은 grad 가 필요 없음. (단순히 손실계산을 위한 것)\n","      \n","      Y = reward_batch + gamma*((1-done_batch)*torch.max(Q2, dim=1)[0])\n","      X = Q1.gather(dim=1, index = action_batch.long().unsqueeze(dim=1)).squeeze()\n","\n","      loss = loss_fn(X,Y.detach()) \n","      \n","      print(i,loss.item())\n","      clear_output(wait=True)\n","      optimizer.zero_grad()\n","      # 최적화기의 매개변수를 0으로 초기화시킨다.\n","      loss.backward() \n","      # 손실을 통해 역전파를 시행한다.\n","      losses.append(loss.item())\n","      # 손실을 리스트에 추가한다.\n","      optimizer.step()\n","      # 최적화기를 발전시킨다.\n","\n","      if j%sync_freq:\n","        # 500회마다 신경망 카피\n","        model2.load_state_dict(model.state_dict())\n","      \n","      if reward != -1 or mov > max_moves:\n","        status = 0\n","        mov = 0\n","      \n","losses = np.array(losses)\n","\n","\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["4999 9.903529644361697e-06\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5hwkZwEdMuuE"},"source":["\n"],"execution_count":null,"outputs":[]}]}